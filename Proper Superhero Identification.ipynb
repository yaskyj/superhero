{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D \n",
    "from keras.layers.convolutional import MaxPooling2D \n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), \n",
    "                     input_shape=(3, 150, 150), \n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    # Compile model\n",
    "    rmsprop = optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5590 images belonging to 12 classes.\n",
      "Found 2455 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rotation_range=180, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   rescale=1./255, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "174/174 [==============================] - 64s 366ms/step - loss: 2.2880 - acc: 0.2298 - val_loss: 2.1748 - val_acc: 0.2603\n",
      "Epoch 2/50\n",
      "174/174 [==============================] - 64s 367ms/step - loss: 2.0420 - acc: 0.3196 - val_loss: 2.0038 - val_acc: 0.3442\n",
      "Epoch 3/50\n",
      "174/174 [==============================] - 64s 366ms/step - loss: 1.9226 - acc: 0.3697 - val_loss: 1.9710 - val_acc: 0.3644\n",
      "Epoch 4/50\n",
      "174/174 [==============================] - 63s 365ms/step - loss: 1.8500 - acc: 0.3954 - val_loss: 1.9228 - val_acc: 0.3615\n",
      "Epoch 5/50\n",
      "174/174 [==============================] - 63s 363ms/step - loss: 1.7914 - acc: 0.4146 - val_loss: 1.9561 - val_acc: 0.3599\n",
      "Epoch 6/50\n",
      "174/174 [==============================] - 63s 361ms/step - loss: 1.7689 - acc: 0.4218 - val_loss: 1.8104 - val_acc: 0.4069\n",
      "Epoch 7/50\n",
      "174/174 [==============================] - 62s 359ms/step - loss: 1.7137 - acc: 0.4380 - val_loss: 1.8374 - val_acc: 0.4193\n",
      "Epoch 8/50\n",
      "174/174 [==============================] - 63s 360ms/step - loss: 1.6803 - acc: 0.4454 - val_loss: 1.8127 - val_acc: 0.4210\n",
      "Epoch 9/50\n",
      "174/174 [==============================] - 62s 357ms/step - loss: 1.6560 - acc: 0.4622 - val_loss: 1.8272 - val_acc: 0.4400\n",
      "Epoch 10/50\n",
      "174/174 [==============================] - 62s 354ms/step - loss: 1.6514 - acc: 0.4715 - val_loss: 1.8378 - val_acc: 0.4197\n",
      "Epoch 11/50\n",
      "174/174 [==============================] - 61s 352ms/step - loss: 1.6189 - acc: 0.4745 - val_loss: 1.8286 - val_acc: 0.4317\n",
      "Epoch 12/50\n",
      "174/174 [==============================] - 62s 356ms/step - loss: 1.6130 - acc: 0.4770 - val_loss: 1.8577 - val_acc: 0.4028\n",
      "Epoch 13/50\n",
      "174/174 [==============================] - 62s 354ms/step - loss: 1.6029 - acc: 0.4905 - val_loss: 1.7564 - val_acc: 0.4515\n",
      "Epoch 14/50\n",
      "174/174 [==============================] - 61s 349ms/step - loss: 1.5693 - acc: 0.4936 - val_loss: 1.7934 - val_acc: 0.4305\n",
      "Epoch 15/50\n",
      "174/174 [==============================] - 63s 362ms/step - loss: 1.5910 - acc: 0.4953 - val_loss: 1.7520 - val_acc: 0.4433\n",
      "Epoch 16/50\n",
      "174/174 [==============================] - 62s 355ms/step - loss: 1.5718 - acc: 0.4958 - val_loss: 1.8577 - val_acc: 0.4470\n",
      "Epoch 17/50\n",
      "174/174 [==============================] - 62s 357ms/step - loss: 1.5538 - acc: 0.5020 - val_loss: 1.7178 - val_acc: 0.4490\n",
      "Epoch 18/50\n",
      "174/174 [==============================] - 62s 357ms/step - loss: 1.5358 - acc: 0.5030 - val_loss: 1.8568 - val_acc: 0.4181\n",
      "Epoch 19/50\n",
      "174/174 [==============================] - 62s 354ms/step - loss: 1.5552 - acc: 0.5011 - val_loss: 1.8032 - val_acc: 0.4585\n",
      "Epoch 20/50\n",
      "174/174 [==============================] - 61s 353ms/step - loss: 1.5409 - acc: 0.5110 - val_loss: 1.7565 - val_acc: 0.4482\n",
      "Epoch 21/50\n",
      "174/174 [==============================] - 61s 352ms/step - loss: 1.5462 - acc: 0.5137 - val_loss: 1.9000 - val_acc: 0.4362\n",
      "Epoch 22/50\n",
      "174/174 [==============================] - 60s 347ms/step - loss: 1.5386 - acc: 0.5187 - val_loss: 1.9204 - val_acc: 0.4226\n",
      "Epoch 23/50\n",
      "174/174 [==============================] - 62s 358ms/step - loss: 1.5567 - acc: 0.5177 - val_loss: 1.7870 - val_acc: 0.4552\n",
      "Epoch 24/50\n",
      "174/174 [==============================] - 63s 361ms/step - loss: 1.5134 - acc: 0.5226 - val_loss: 1.8203 - val_acc: 0.4338\n",
      "Epoch 25/50\n",
      "174/174 [==============================] - 62s 355ms/step - loss: 1.5502 - acc: 0.5090 - val_loss: 1.8335 - val_acc: 0.4383\n",
      "Epoch 26/50\n",
      "174/174 [==============================] - 62s 356ms/step - loss: 1.5300 - acc: 0.5190 - val_loss: 1.8139 - val_acc: 0.4218\n",
      "Epoch 27/50\n",
      "174/174 [==============================] - 61s 352ms/step - loss: 1.5414 - acc: 0.5212 - val_loss: 1.8020 - val_acc: 0.4094\n",
      "Epoch 28/50\n",
      "174/174 [==============================] - 62s 357ms/step - loss: 1.5198 - acc: 0.5289 - val_loss: 1.8546 - val_acc: 0.4366\n",
      "Epoch 29/50\n",
      "174/174 [==============================] - 62s 358ms/step - loss: 1.5324 - acc: 0.5275 - val_loss: 1.7398 - val_acc: 0.4424\n",
      "Epoch 00029: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f54081abd90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(monitor='val_acc', patience=10, verbose=1)\n",
    "# build the model\n",
    "model = larger_model()\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=5590//batch_size, \n",
    "                    epochs=50, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=2455//batch_size, \n",
    "                    callbacks=[early_stopping_monitor], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "174/174 [==============================] - 64s 366ms/step - loss: 2.2880 - acc: 0.2298 - val_loss: 2.1748 - val_acc: 0.2603\n",
      "Epoch 2/50\n",
      "174/174 [==============================] - 64s 367ms/step - loss: 2.0420 - acc: 0.3196 - val_loss: 2.0038 - val_acc: 0.3442\n",
      "Epoch 3/50\n",
      " 66/174 [==========>...................] - ETA: 36s - loss: 1.9397 - acc: 0.3563"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = larger_model()\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=5590//batch_size, \n",
    "                    epochs=50, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=2455//batch_size, \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False)  # keep data in same order as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict_generator(generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = probabilities.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(0, len(y_classes)):    \n",
    "    for hero, cls in validation_generator.class_indices.iteritems():\n",
    "        if cls == y_classes[i]:\n",
    "            predictions.append([generator.filenames[i], hero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submission = pd.DataFrame(data=predictions, \n",
    "                          columns=['filename', 'Superhero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submission['filename'] = temp_submission['filename'].str.slice(5)\n",
    "temp_submission['filename'] = temp_submission['filename'].str.slice(0,-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('Superhero_Submission_Format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.drop(['Superhero'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.merge(submission, temp_submission,\n",
    "              on='filename') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.Superhero.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
