{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D \n",
    "from keras.layers.convolutional import MaxPooling2D \n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), \n",
    "                     input_shape=(3, 150, 150), \n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4346 images belonging to 12 classes.\n",
      "Found 1087 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rotation_range=180, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   rescale=1./255, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "271/271 [==============================] - 29s 107ms/step - loss: 2.2910 - acc: 0.2201 - val_loss: 2.1314 - val_acc: 0.2743\n",
      "Epoch 2/50\n",
      "271/271 [==============================] - 29s 107ms/step - loss: 2.1000 - acc: 0.3080 - val_loss: 1.9702 - val_acc: 0.3567\n",
      "Epoch 3/50\n",
      "271/271 [==============================] - 29s 107ms/step - loss: 1.9885 - acc: 0.3416 - val_loss: 1.8719 - val_acc: 0.39031s - loss: 1\n",
      "Epoch 4/50\n",
      "271/271 [==============================] - 29s 106ms/step - loss: 1.9335 - acc: 0.3688 - val_loss: 1.8638 - val_acc: 0.3866\n",
      "Epoch 5/50\n",
      "271/271 [==============================] - 29s 107ms/step - loss: 1.8767 - acc: 0.3856 - val_loss: 1.7439 - val_acc: 0.4435\n",
      "Epoch 6/50\n",
      "271/271 [==============================] - 29s 106ms/step - loss: 1.8526 - acc: 0.4033 - val_loss: 1.7604 - val_acc: 0.4323\n",
      "Epoch 7/50\n",
      "271/271 [==============================] - 29s 106ms/step - loss: 1.8227 - acc: 0.4052 - val_loss: 1.6875 - val_acc: 0.4585\n",
      "Epoch 8/50\n",
      "271/271 [==============================] - 29s 107ms/step - loss: 1.7985 - acc: 0.4132 - val_loss: 1.6792 - val_acc: 0.4463\n",
      "Epoch 9/50\n",
      "271/271 [==============================] - 29s 106ms/step - loss: 1.7752 - acc: 0.4170 - val_loss: 1.6712 - val_acc: 0.4472\n",
      "Epoch 10/50\n",
      "271/271 [==============================] - 28s 105ms/step - loss: 1.7501 - acc: 0.4232 - val_loss: 1.6559 - val_acc: 0.4500\n",
      "Epoch 11/50\n",
      "271/271 [==============================] - 28s 105ms/step - loss: 1.7444 - acc: 0.4317 - val_loss: 1.6056 - val_acc: 0.4669\n",
      "Epoch 12/50\n",
      "271/271 [==============================] - 29s 107ms/step - loss: 1.7008 - acc: 0.4299 - val_loss: 1.5870 - val_acc: 0.4687\n",
      "Epoch 13/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.6939 - acc: 0.4446 - val_loss: 1.5857 - val_acc: 0.4958\n",
      "Epoch 14/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.7061 - acc: 0.4447 - val_loss: 1.5576 - val_acc: 0.4902\n",
      "Epoch 15/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.6550 - acc: 0.4475 - val_loss: 1.5873 - val_acc: 0.4790\n",
      "Epoch 16/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.6608 - acc: 0.4590 - val_loss: 1.5268 - val_acc: 0.4883\n",
      "Epoch 17/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.6247 - acc: 0.4691 - val_loss: 1.5049 - val_acc: 0.4921\n",
      "Epoch 18/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.6370 - acc: 0.4710 - val_loss: 1.5479 - val_acc: 0.4995\n",
      "Epoch 19/50\n",
      "271/271 [==============================] - 28s 105ms/step - loss: 1.6063 - acc: 0.4779 - val_loss: 1.6145 - val_acc: 0.4734\n",
      "Epoch 20/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.6189 - acc: 0.4652 - val_loss: 1.7064 - val_acc: 0.4538\n",
      "Epoch 21/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.6005 - acc: 0.4691 - val_loss: 1.4909 - val_acc: 0.5070\n",
      "Epoch 22/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.5939 - acc: 0.4779 - val_loss: 1.5371 - val_acc: 0.5023\n",
      "Epoch 23/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.5723 - acc: 0.4791 - val_loss: 1.4431 - val_acc: 0.5089\n",
      "Epoch 24/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.5921 - acc: 0.4772 - val_loss: 1.5377 - val_acc: 0.4986\n",
      "Epoch 25/50\n",
      "271/271 [==============================] - 29s 106ms/step - loss: 1.5803 - acc: 0.4794 - val_loss: 1.4559 - val_acc: 0.5154\n",
      "Epoch 26/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.5432 - acc: 0.4957 - val_loss: 1.5011 - val_acc: 0.5126\n",
      "Epoch 27/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.5327 - acc: 0.5040 - val_loss: 1.5299 - val_acc: 0.4902\n",
      "Epoch 28/50\n",
      "271/271 [==============================] - 28s 105ms/step - loss: 1.5420 - acc: 0.4933 - val_loss: 1.5584 - val_acc: 0.4893\n",
      "Epoch 29/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.5246 - acc: 0.5109 - val_loss: 1.5188 - val_acc: 0.5135\n",
      "Epoch 30/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.5085 - acc: 0.5180 - val_loss: 1.5507 - val_acc: 0.5350\n",
      "Epoch 31/50\n",
      "271/271 [==============================] - 28s 105ms/step - loss: 1.5223 - acc: 0.4952 - val_loss: 1.5299 - val_acc: 0.5257\n",
      "Epoch 32/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.4518 - acc: 0.5278 - val_loss: 1.5071 - val_acc: 0.5303\n",
      "Epoch 33/50\n",
      "271/271 [==============================] - 28s 105ms/step - loss: 1.4849 - acc: 0.5151 - val_loss: 1.3863 - val_acc: 0.5341\n",
      "Epoch 34/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.4824 - acc: 0.5162 - val_loss: 1.5842 - val_acc: 0.4967\n",
      "Epoch 35/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.4716 - acc: 0.5231 - val_loss: 1.4665 - val_acc: 0.5089\n",
      "Epoch 36/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.4457 - acc: 0.5284 - val_loss: 1.4455 - val_acc: 0.5322\n",
      "Epoch 37/50\n",
      "271/271 [==============================] - 28s 103ms/step - loss: 1.4774 - acc: 0.5311 - val_loss: 1.4052 - val_acc: 0.5313\n",
      "Epoch 38/50\n",
      "271/271 [==============================] - 28s 105ms/step - loss: 1.4268 - acc: 0.5325 - val_loss: 1.5490 - val_acc: 0.4977\n",
      "Epoch 39/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.4411 - acc: 0.5412 - val_loss: 1.4492 - val_acc: 0.5303\n",
      "Epoch 40/50\n",
      "271/271 [==============================] - 28s 104ms/step - loss: 1.4169 - acc: 0.5397 - val_loss: 1.5666 - val_acc: 0.4949\n",
      "Epoch 00040: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71ed2e4b50>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(monitor='val_acc', patience=10, verbose=1)\n",
    "# build the model\n",
    "model = larger_model()\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=4346//batch_size, \n",
    "                    epochs=50, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=1087//batch_size, \n",
    "                    callbacks=[early_stopping_monitor], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3375 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False)  # keep data in same order as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/211 [==============================] - 4s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.predict_generator(generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = probabilities.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(0, len(y_classes)):    \n",
    "    for hero, cls in validation_generator.class_indices.iteritems():\n",
    "        if cls == y_classes[i]:\n",
    "            predictions.append([generator.filenames[i], hero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submission = pd.DataFrame(data=predictions, \n",
    "                          columns=['filename', 'Superhero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submission['filename'] = temp_submission['filename'].str.slice(5)\n",
    "temp_submission['filename'] = temp_submission['filename'].str.slice(0,-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('Superhero_Submission_Format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.drop(['Superhero'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.merge(submission, temp_submission,\n",
    "              on='filename') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spider_man', 'super_man', 'iron_man', 'black_panther', 'bat_man',\n",
       "       'captain_america', 'hulk', 'avengers', 'aqua_man', 'cat_woman',\n",
       "       'ghostrider', 'ant_man'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.Superhero.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
