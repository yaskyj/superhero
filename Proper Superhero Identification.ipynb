{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(3, 150, 150)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(32,(3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64,(3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    rmsprop = optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3800 images belonging to 12 classes.\n",
      "Found 1633 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rotation_range=180, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   rescale=1./255, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train_Original/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train_Original/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "118/118 [==============================] - 27s 228ms/step - loss: 2.3577 - acc: 0.2458 - val_loss: 2.1465 - val_acc: 0.2604\n",
      "Epoch 2/50\n",
      "118/118 [==============================] - 27s 226ms/step - loss: 1.9912 - acc: 0.3542 - val_loss: 1.9655 - val_acc: 0.3685\n",
      "Epoch 3/50\n",
      "118/118 [==============================] - 26s 224ms/step - loss: 1.8813 - acc: 0.4053 - val_loss: 1.9646 - val_acc: 0.3941\n",
      "Epoch 4/50\n",
      "118/118 [==============================] - 26s 224ms/step - loss: 1.7619 - acc: 0.4405 - val_loss: 1.7698 - val_acc: 0.4235\n",
      "Epoch 5/50\n",
      "118/118 [==============================] - 26s 218ms/step - loss: 1.7254 - acc: 0.4576 - val_loss: 1.7251 - val_acc: 0.4360\n",
      "Epoch 6/50\n",
      "118/118 [==============================] - 26s 219ms/step - loss: 1.6642 - acc: 0.4788 - val_loss: 1.7579 - val_acc: 0.4428\n",
      "Epoch 7/50\n",
      "118/118 [==============================] - 26s 222ms/step - loss: 1.6570 - acc: 0.4830 - val_loss: 1.7251 - val_acc: 0.4379\n",
      "Epoch 8/50\n",
      "118/118 [==============================] - 26s 221ms/step - loss: 1.6393 - acc: 0.4951 - val_loss: 1.8174 - val_acc: 0.4072ss: 1.6371 - acc: 0.495\n",
      "Epoch 9/50\n",
      "118/118 [==============================] - 26s 220ms/step - loss: 1.6250 - acc: 0.4981 - val_loss: 1.6973 - val_acc: 0.4585\n",
      "Epoch 10/50\n",
      "118/118 [==============================] - 26s 223ms/step - loss: 1.5386 - acc: 0.5130 - val_loss: 1.5760 - val_acc: 0.4741\n",
      "Epoch 11/50\n",
      "118/118 [==============================] - 26s 224ms/step - loss: 1.5442 - acc: 0.5177 - val_loss: 1.5945 - val_acc: 0.4722\n",
      "Epoch 12/50\n",
      "118/118 [==============================] - 26s 224ms/step - loss: 1.5292 - acc: 0.5245 - val_loss: 1.5666 - val_acc: 0.4685\n",
      "Epoch 13/50\n",
      "118/118 [==============================] - 26s 217ms/step - loss: 1.5097 - acc: 0.5232 - val_loss: 1.5573 - val_acc: 0.4953\n",
      "Epoch 14/50\n",
      "118/118 [==============================] - 26s 221ms/step - loss: 1.5007 - acc: 0.5282 - val_loss: 1.7147 - val_acc: 0.4647\n",
      "Epoch 15/50\n",
      "118/118 [==============================] - 26s 216ms/step - loss: 1.4745 - acc: 0.5521 - val_loss: 1.6270 - val_acc: 0.4735\n",
      "Epoch 16/50\n",
      "118/118 [==============================] - 26s 221ms/step - loss: 1.4947 - acc: 0.5260 - val_loss: 1.6229 - val_acc: 0.4641\n",
      "Epoch 17/50\n",
      "118/118 [==============================] - 26s 218ms/step - loss: 1.4759 - acc: 0.5347 - val_loss: 1.5499 - val_acc: 0.4872\n",
      "Epoch 18/50\n",
      "118/118 [==============================] - 25s 215ms/step - loss: 1.4799 - acc: 0.5435 - val_loss: 1.5323 - val_acc: 0.4884\n",
      "Epoch 19/50\n",
      "118/118 [==============================] - 25s 214ms/step - loss: 1.4616 - acc: 0.5479 - val_loss: 1.5943 - val_acc: 0.4872\n",
      "Epoch 20/50\n",
      "118/118 [==============================] - 25s 214ms/step - loss: 1.4394 - acc: 0.5565 - val_loss: 1.5748 - val_acc: 0.4859\n",
      "Epoch 21/50\n",
      "118/118 [==============================] - 26s 216ms/step - loss: 1.4749 - acc: 0.5403 - val_loss: 1.6117 - val_acc: 0.4928\n",
      "Epoch 22/50\n",
      "118/118 [==============================] - 25s 214ms/step - loss: 1.4606 - acc: 0.5504 - val_loss: 1.6441 - val_acc: 0.5122\n",
      "Epoch 23/50\n",
      "118/118 [==============================] - 26s 219ms/step - loss: 1.4692 - acc: 0.5513 - val_loss: 1.9567 - val_acc: 0.4491\n",
      "Epoch 24/50\n",
      "118/118 [==============================] - 25s 215ms/step - loss: 1.4595 - acc: 0.5493 - val_loss: 1.6999 - val_acc: 0.4816\n",
      "Epoch 25/50\n",
      "118/118 [==============================] - 25s 215ms/step - loss: 1.4572 - acc: 0.5523 - val_loss: 1.7055 - val_acc: 0.4460\n",
      "Epoch 26/50\n",
      "118/118 [==============================] - 25s 214ms/step - loss: 1.4647 - acc: 0.5506 - val_loss: 1.6501 - val_acc: 0.4666\n",
      "Epoch 27/50\n",
      "118/118 [==============================] - 25s 210ms/step - loss: 1.4600 - acc: 0.5539 - val_loss: 1.7158 - val_acc: 0.4616\n",
      "Epoch 28/50\n",
      "118/118 [==============================] - 25s 215ms/step - loss: 1.4422 - acc: 0.5657 - val_loss: 1.6626 - val_acc: 0.4916\n",
      "Epoch 29/50\n",
      "118/118 [==============================] - 25s 213ms/step - loss: 1.4496 - acc: 0.5583 - val_loss: 1.5452 - val_acc: 0.5203\n",
      "Epoch 30/50\n",
      "118/118 [==============================] - 26s 217ms/step - loss: 1.4666 - acc: 0.5538 - val_loss: 1.8461 - val_acc: 0.4447\n",
      "Epoch 31/50\n",
      "118/118 [==============================] - 25s 209ms/step - loss: 1.4732 - acc: 0.5516 - val_loss: 1.6500 - val_acc: 0.4853\n",
      "Epoch 32/50\n",
      "118/118 [==============================] - 25s 212ms/step - loss: 1.4788 - acc: 0.5391 - val_loss: 1.8179 - val_acc: 0.4809\n",
      "Epoch 33/50\n",
      "118/118 [==============================] - 25s 210ms/step - loss: 1.4487 - acc: 0.5577 - val_loss: 1.8187 - val_acc: 0.4485\n",
      "Epoch 34/50\n",
      "118/118 [==============================] - 25s 213ms/step - loss: 1.4286 - acc: 0.5605 - val_loss: 1.6825 - val_acc: 0.4666\n",
      "Epoch 35/50\n",
      "118/118 [==============================] - 25s 213ms/step - loss: 1.4783 - acc: 0.5336 - val_loss: 1.5884 - val_acc: 0.4803\n",
      "Epoch 36/50\n",
      "118/118 [==============================] - 25s 213ms/step - loss: 1.4428 - acc: 0.5569 - val_loss: 1.6253 - val_acc: 0.4653\n",
      "Epoch 37/50\n",
      "118/118 [==============================] - 25s 214ms/step - loss: 1.4577 - acc: 0.5487 - val_loss: 1.6665 - val_acc: 0.4753\n",
      "Epoch 38/50\n",
      "118/118 [==============================] - 25s 214ms/step - loss: 1.4771 - acc: 0.5566 - val_loss: 1.7199 - val_acc: 0.4472\n",
      "Epoch 39/50\n",
      "118/118 [==============================] - 25s 210ms/step - loss: 1.5166 - acc: 0.5443 - val_loss: 1.6573 - val_acc: 0.4809ETA: 1s - loss: 1.5218 - a\n",
      "Epoch 00039: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f0475dbd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(monitor='val_acc', patience=10, verbose=1)\n",
    "# build the model\n",
    "model = cnn_model()\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=3800//batch_size, \n",
    "                    epochs=50, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=1633//batch_size, \n",
    "                    callbacks=[early_stopping_monitor], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3375 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False)  # keep data in same order as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 6s 56ms/step\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.predict_generator(generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = probabilities.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(0, len(y_classes)):    \n",
    "    for hero, cls in validation_generator.class_indices.iteritems():\n",
    "        if cls == y_classes[i]:\n",
    "            predictions.append([generator.filenames[i], hero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submission = pd.DataFrame(data=predictions, \n",
    "                          columns=['filename', 'Superhero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submission['filename'] = temp_submission['filename'].str.slice(5)\n",
    "temp_submission['filename'] = temp_submission['filename'].str.slice(0,-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('Superhero_Submission_Format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.drop(['Superhero'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.merge(submission, temp_submission,\n",
    "              on='filename') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spider_man', 'super_man', 'iron_man', 'black_panther', 'aqua_man',\n",
       "       'bat_man', 'captain_america', 'cat_woman', 'hulk', 'avengers',\n",
       "       'ant_man', 'ghostrider'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.Superhero.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
