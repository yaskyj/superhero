{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(3, 150, 150)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(32,(3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64,(3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    rmsprop = optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4890 images belonging to 12 classes.\n",
      "Found 531 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rotation_range=180, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   rescale=1./255, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train_Original/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train_Original/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "152/152 [==============================] - 34s 225ms/step - loss: 2.4734 - acc: 0.2323 - val_loss: 2.2511 - val_acc: 0.2500\n",
      "Epoch 2/50\n",
      "152/152 [==============================] - 32s 209ms/step - loss: 2.0475 - acc: 0.3260 - val_loss: 1.9305 - val_acc: 0.3487\n",
      "Epoch 3/50\n",
      "152/152 [==============================] - 33s 216ms/step - loss: 1.8881 - acc: 0.3904 - val_loss: 1.6827 - val_acc: 0.4549\n",
      "Epoch 4/50\n",
      "152/152 [==============================] - 32s 211ms/step - loss: 1.8067 - acc: 0.4193 - val_loss: 1.8101 - val_acc: 0.4409\n",
      "Epoch 5/50\n",
      "152/152 [==============================] - 31s 206ms/step - loss: 1.7273 - acc: 0.4528 - val_loss: 1.6376 - val_acc: 0.4790\n",
      "Epoch 6/50\n",
      "152/152 [==============================] - 32s 211ms/step - loss: 1.6855 - acc: 0.4645 - val_loss: 1.7659 - val_acc: 0.4429\n",
      "Epoch 7/50\n",
      "152/152 [==============================] - 32s 211ms/step - loss: 1.6539 - acc: 0.4690 - val_loss: 1.5430 - val_acc: 0.5130\n",
      "Epoch 8/50\n",
      "152/152 [==============================] - 32s 209ms/step - loss: 1.6315 - acc: 0.4836 - val_loss: 1.5233 - val_acc: 0.5170\n",
      "Epoch 9/50\n",
      "152/152 [==============================] - 33s 215ms/step - loss: 1.5958 - acc: 0.4862 - val_loss: 1.5692 - val_acc: 0.4649\n",
      "Epoch 10/50\n",
      "152/152 [==============================] - 33s 215ms/step - loss: 1.5527 - acc: 0.5063 - val_loss: 2.0170 - val_acc: 0.4790\n",
      "Epoch 11/50\n",
      "152/152 [==============================] - 32s 211ms/step - loss: 1.5920 - acc: 0.4904 - val_loss: 1.4945 - val_acc: 0.5090\n",
      "Epoch 12/50\n",
      "152/152 [==============================] - 32s 209ms/step - loss: 1.5510 - acc: 0.5103 - val_loss: 1.5020 - val_acc: 0.5050\n",
      "Epoch 13/50\n",
      "152/152 [==============================] - 32s 209ms/step - loss: 1.5448 - acc: 0.5080 - val_loss: 1.5543 - val_acc: 0.5050\n",
      "Epoch 14/50\n",
      "152/152 [==============================] - 31s 206ms/step - loss: 1.5287 - acc: 0.5063 - val_loss: 1.5394 - val_acc: 0.4790\n",
      "Epoch 15/50\n",
      "152/152 [==============================] - 32s 208ms/step - loss: 1.5222 - acc: 0.5180 - val_loss: 1.5920 - val_acc: 0.4389\n",
      "Epoch 16/50\n",
      "152/152 [==============================] - 32s 210ms/step - loss: 1.5327 - acc: 0.5142 - val_loss: 1.5738 - val_acc: 0.5010\n",
      "Epoch 17/50\n",
      "152/152 [==============================] - 32s 207ms/step - loss: 1.5307 - acc: 0.5172 - val_loss: 1.4478 - val_acc: 0.5251\n",
      "Epoch 18/50\n",
      "152/152 [==============================] - 32s 210ms/step - loss: 1.4868 - acc: 0.5295 - val_loss: 2.1294 - val_acc: 0.4551\n",
      "Epoch 19/50\n",
      "152/152 [==============================] - 31s 206ms/step - loss: 1.5442 - acc: 0.5100 - val_loss: 1.4252 - val_acc: 0.5110\n",
      "Epoch 20/50\n",
      "152/152 [==============================] - 32s 208ms/step - loss: 1.4976 - acc: 0.5271 - val_loss: 1.5385 - val_acc: 0.5010\n",
      "Epoch 21/50\n",
      "152/152 [==============================] - 32s 213ms/step - loss: 1.4801 - acc: 0.5292 - val_loss: 1.7120 - val_acc: 0.4790\n",
      "Epoch 22/50\n",
      "152/152 [==============================] - 32s 207ms/step - loss: 1.5141 - acc: 0.5273 - val_loss: 2.2812 - val_acc: 0.4289\n",
      "Epoch 23/50\n",
      "152/152 [==============================] - 32s 209ms/step - loss: 1.4782 - acc: 0.5403 - val_loss: 1.4075 - val_acc: 0.5551\n",
      "Epoch 24/50\n",
      "152/152 [==============================] - 32s 212ms/step - loss: 1.4889 - acc: 0.5403 - val_loss: 1.5791 - val_acc: 0.4850\n",
      "Epoch 25/50\n",
      "152/152 [==============================] - 32s 208ms/step - loss: 1.4761 - acc: 0.5307 - val_loss: 1.6506 - val_acc: 0.5251\n",
      "Epoch 26/50\n",
      "152/152 [==============================] - 32s 208ms/step - loss: 1.4906 - acc: 0.5269 - val_loss: 1.4370 - val_acc: 0.5511\n",
      "Epoch 27/50\n",
      "152/152 [==============================] - 32s 214ms/step - loss: 1.5012 - acc: 0.5290 - val_loss: 1.8676 - val_acc: 0.4429\n",
      "Epoch 28/50\n",
      "152/152 [==============================] - 31s 206ms/step - loss: 1.4978 - acc: 0.5389 - val_loss: 1.7618 - val_acc: 0.5110\n",
      "Epoch 29/50\n",
      "152/152 [==============================] - 32s 210ms/step - loss: 1.5015 - acc: 0.5439 - val_loss: 1.6255 - val_acc: 0.4930\n",
      "Epoch 30/50\n",
      "152/152 [==============================] - 32s 209ms/step - loss: 1.5042 - acc: 0.5337 - val_loss: 1.4344 - val_acc: 0.5792\n",
      "Epoch 31/50\n",
      "152/152 [==============================] - 31s 204ms/step - loss: 1.5045 - acc: 0.5304 - val_loss: 1.5417 - val_acc: 0.4910\n",
      "Epoch 32/50\n",
      "152/152 [==============================] - 32s 209ms/step - loss: 1.4904 - acc: 0.5316 - val_loss: 1.6423 - val_acc: 0.5331\n",
      "Epoch 33/50\n",
      "152/152 [==============================] - 31s 205ms/step - loss: 1.5022 - acc: 0.5260 - val_loss: 1.5083 - val_acc: 0.5611\n",
      "Epoch 34/50\n",
      "152/152 [==============================] - 31s 205ms/step - loss: 1.4846 - acc: 0.5384 - val_loss: 1.5912 - val_acc: 0.5130\n",
      "Epoch 35/50\n",
      "152/152 [==============================] - 31s 204ms/step - loss: 1.4941 - acc: 0.5522 - val_loss: 1.4893 - val_acc: 0.5527\n",
      "Epoch 36/50\n",
      "152/152 [==============================] - 32s 208ms/step - loss: 1.5351 - acc: 0.5267 - val_loss: 1.5063 - val_acc: 0.5291\n",
      "Epoch 37/50\n",
      "152/152 [==============================] - 32s 208ms/step - loss: 1.4813 - acc: 0.5438 - val_loss: 1.8414 - val_acc: 0.4689\n",
      "Epoch 38/50\n",
      "152/152 [==============================] - 32s 209ms/step - loss: 1.5188 - acc: 0.5286 - val_loss: 1.4104 - val_acc: 0.5611\n",
      "Epoch 39/50\n",
      "152/152 [==============================] - 31s 205ms/step - loss: 1.5136 - acc: 0.5262 - val_loss: 1.5434 - val_acc: 0.5090\n",
      "Epoch 40/50\n",
      "152/152 [==============================] - 31s 205ms/step - loss: 1.4791 - acc: 0.5481 - val_loss: 3.4179 - val_acc: 0.3808\n",
      "Epoch 00040: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9b87752a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(monitor='val_acc', patience=10, verbose=1)\n",
    "# build the model\n",
    "model = cnn_model()\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=4890//batch_size, \n",
    "                    epochs=50, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=531//batch_size, \n",
    "                    callbacks=[early_stopping_monitor], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3375 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False)  # keep data in same order as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 6s 59ms/step\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.predict_generator(generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = probabilities.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(0, len(y_classes)):    \n",
    "    for hero, cls in validation_generator.class_indices.iteritems():\n",
    "        if cls == y_classes[i]:\n",
    "            predictions.append([generator.filenames[i], hero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submission = pd.DataFrame(data=predictions, \n",
    "                          columns=['filename', 'Superhero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submission['filename'] = temp_submission['filename'].str.slice(5)\n",
    "temp_submission['filename'] = temp_submission['filename'].str.slice(0,-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('Superhero_Submission_Format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.drop(['Superhero'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.merge(submission, temp_submission,\n",
    "              on='filename') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spider_man', 'super_man', 'iron_man', 'black_panther', 'bat_man',\n",
       "       'aqua_man', 'hulk', 'ghostrider', 'avengers', 'ant_man',\n",
       "       'cat_woman', 'captain_america'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.Superhero.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
