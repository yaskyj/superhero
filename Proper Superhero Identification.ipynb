{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/matplotlib/__init__.py:962: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(3, 150, 150)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(32,(3,3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64,(3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64,(3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    rmsprop = optimizers.RMSprop(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3256 images belonging to 12 classes.\n",
      "Found 2165 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rotation_range=180, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   rescale=1./255, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train_Original/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train_Original/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "101/101 [==============================] - 24s 236ms/step - loss: 2.5131 - acc: 0.2081 - val_loss: 2.0652 - val_acc: 0.3167\n",
      "Epoch 2/50\n",
      "101/101 [==============================] - 23s 231ms/step - loss: 2.0726 - acc: 0.3201 - val_loss: 2.0561 - val_acc: 0.3301\n",
      "Epoch 3/50\n",
      "101/101 [==============================] - 23s 229ms/step - loss: 1.9444 - acc: 0.3616 - val_loss: 2.0564 - val_acc: 0.3343\n",
      "Epoch 4/50\n",
      "101/101 [==============================] - 23s 232ms/step - loss: 1.8668 - acc: 0.3847 - val_loss: 1.8492 - val_acc: 0.3915\n",
      "Epoch 5/50\n",
      "101/101 [==============================] - 23s 231ms/step - loss: 1.8035 - acc: 0.4070 - val_loss: 1.7067 - val_acc: 0.4313\n",
      "Epoch 6/50\n",
      "101/101 [==============================] - 23s 225ms/step - loss: 1.7551 - acc: 0.4273 - val_loss: 1.6383 - val_acc: 0.4566\n",
      "Epoch 7/50\n",
      "101/101 [==============================] - 24s 235ms/step - loss: 1.7454 - acc: 0.4348 - val_loss: 1.7151 - val_acc: 0.4543\n",
      "Epoch 8/50\n",
      "101/101 [==============================] - 24s 235ms/step - loss: 1.6995 - acc: 0.4487 - val_loss: 1.6364 - val_acc: 0.4510\n",
      "Epoch 9/50\n",
      "101/101 [==============================] - 23s 230ms/step - loss: 1.6566 - acc: 0.4614 - val_loss: 1.7216 - val_acc: 0.4576\n",
      "Epoch 10/50\n",
      "101/101 [==============================] - 24s 234ms/step - loss: 1.6606 - acc: 0.4658 - val_loss: 1.7233 - val_acc: 0.4735\n",
      "Epoch 11/50\n",
      "101/101 [==============================] - 23s 227ms/step - loss: 1.6206 - acc: 0.4799 - val_loss: 1.5917 - val_acc: 0.4932\n",
      "Epoch 12/50\n",
      "101/101 [==============================] - 23s 232ms/step - loss: 1.5983 - acc: 0.4822 - val_loss: 1.6646 - val_acc: 0.4768\n",
      "Epoch 13/50\n",
      "101/101 [==============================] - 23s 225ms/step - loss: 1.5811 - acc: 0.4841 - val_loss: 1.7074 - val_acc: 0.4923\n",
      "Epoch 14/50\n",
      "101/101 [==============================] - 23s 231ms/step - loss: 1.5731 - acc: 0.4998 - val_loss: 1.4582 - val_acc: 0.5345\n",
      "Epoch 15/50\n",
      "101/101 [==============================] - 23s 228ms/step - loss: 1.5599 - acc: 0.4895 - val_loss: 1.5968 - val_acc: 0.4834\n",
      "Epoch 16/50\n",
      "101/101 [==============================] - 23s 227ms/step - loss: 1.5439 - acc: 0.5009 - val_loss: 1.5722 - val_acc: 0.5096\n",
      "Epoch 17/50\n",
      "101/101 [==============================] - 22s 220ms/step - loss: 1.5134 - acc: 0.5023 - val_loss: 1.5660 - val_acc: 0.5138\n",
      "Epoch 18/50\n",
      "101/101 [==============================] - 23s 225ms/step - loss: 1.5652 - acc: 0.5028 - val_loss: 1.6198 - val_acc: 0.4871\n",
      "Epoch 19/50\n",
      "101/101 [==============================] - 22s 221ms/step - loss: 1.5043 - acc: 0.5186 - val_loss: 1.5374 - val_acc: 0.5391\n",
      "Epoch 20/50\n",
      "101/101 [==============================] - 22s 223ms/step - loss: 1.5208 - acc: 0.5098 - val_loss: 1.5055 - val_acc: 0.5176\n",
      "Epoch 21/50\n",
      "101/101 [==============================] - 22s 219ms/step - loss: 1.5047 - acc: 0.5190 - val_loss: 1.6997 - val_acc: 0.5110\n",
      "Epoch 22/50\n",
      "101/101 [==============================] - 23s 226ms/step - loss: 1.5157 - acc: 0.5179 - val_loss: 1.6762 - val_acc: 0.5054\n",
      "Epoch 23/50\n",
      "101/101 [==============================] - 23s 228ms/step - loss: 1.4602 - acc: 0.5298 - val_loss: 1.5657 - val_acc: 0.5120\n",
      "Epoch 24/50\n",
      "101/101 [==============================] - 22s 219ms/step - loss: 1.4931 - acc: 0.5309 - val_loss: 1.6175 - val_acc: 0.5546.4928 - acc: \n",
      "Epoch 25/50\n",
      "101/101 [==============================] - 22s 217ms/step - loss: 1.4745 - acc: 0.5252 - val_loss: 1.5549 - val_acc: 0.5424\n",
      "Epoch 26/50\n",
      "101/101 [==============================] - 23s 225ms/step - loss: 1.4905 - acc: 0.5154 - val_loss: 1.5071 - val_acc: 0.5345\n",
      "Epoch 27/50\n",
      "101/101 [==============================] - 22s 221ms/step - loss: 1.4838 - acc: 0.5247 - val_loss: 1.4685 - val_acc: 0.5532\n",
      "Epoch 28/50\n",
      "101/101 [==============================] - 22s 218ms/step - loss: 1.4643 - acc: 0.5339 - val_loss: 1.6033 - val_acc: 0.5180\n",
      "Epoch 29/50\n",
      "101/101 [==============================] - 22s 216ms/step - loss: 1.4834 - acc: 0.5241 - val_loss: 1.6012 - val_acc: 0.5166\n",
      "Epoch 30/50\n",
      "101/101 [==============================] - 22s 220ms/step - loss: 1.4734 - acc: 0.5379 - val_loss: 1.5974 - val_acc: 0.5363\n",
      "Epoch 31/50\n",
      "101/101 [==============================] - 22s 218ms/step - loss: 1.4677 - acc: 0.5338 - val_loss: 2.0405 - val_acc: 0.4646\n",
      "Epoch 32/50\n",
      "101/101 [==============================] - 22s 219ms/step - loss: 1.4448 - acc: 0.5460 - val_loss: 1.4815 - val_acc: 0.5424\n",
      "Epoch 33/50\n",
      "101/101 [==============================] - 22s 217ms/step - loss: 1.4802 - acc: 0.5300 - val_loss: 1.6279 - val_acc: 0.5213\n",
      "Epoch 34/50\n",
      "101/101 [==============================] - 22s 219ms/step - loss: 1.5004 - acc: 0.5172 - val_loss: 1.4905 - val_acc: 0.5457\n",
      "Epoch 00034: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6064461b90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(monitor='val_acc', patience=10, verbose=1)\n",
    "# build the model\n",
    "model = cnn_model()\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=3256//batch_size, \n",
    "                    epochs=50, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=2165//batch_size, \n",
    "                    callbacks=[early_stopping_monitor], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3375 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False)  # keep data in same order as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 4s 40ms/step\n"
     ]
    }
   ],
   "source": [
    "probabilities = model.predict_generator(generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = probabilities.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(0, len(y_classes)):    \n",
    "    for hero, cls in validation_generator.class_indices.iteritems():\n",
    "        if cls == y_classes[i]:\n",
    "            predictions.append([generator.filenames[i], hero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submission = pd.DataFrame(data=predictions, \n",
    "                          columns=['filename', 'Superhero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_submission['filename'] = temp_submission['filename'].str.slice(5)\n",
    "temp_submission['filename'] = temp_submission['filename'].str.slice(0,-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('Superhero_Submission_Format.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.drop(['Superhero'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.merge(submission, temp_submission,\n",
    "              on='filename') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spider_man', 'super_man', 'iron_man', 'black_panther', 'bat_man',\n",
       "       'cat_woman', 'hulk', 'avengers', 'ant_man', 'aqua_man',\n",
       "       'captain_america', 'ghostrider'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.Superhero.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p27)",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
