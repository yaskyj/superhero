{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D \n",
    "from keras.layers.convolutional import MaxPooling2D \n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), \n",
    "                     input_shape=(3, 150, 150), \n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(12, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4346 images belonging to 12 classes.\n",
      "Found 1087 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(rotation_range=40, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   rescale=1./255, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train/train',  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Train/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "271/271 [==============================] - 564s 2s/step - loss: 2.3249 - acc: 0.1987 - val_loss: 2.2252 - val_acc: 0.2631\n",
      "Epoch 2/50\n",
      "271/271 [==============================] - 561s 2s/step - loss: 2.1700 - acc: 0.2533 - val_loss: 2.0314 - val_acc: 0.2873\n",
      "Epoch 3/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 2.0540 - acc: 0.2960 - val_loss: 1.9539 - val_acc: 0.3340\n",
      "Epoch 4/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.9917 - acc: 0.3159 - val_loss: 1.8428 - val_acc: 0.3582\n",
      "Epoch 5/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.9385 - acc: 0.3512 - val_loss: 1.7953 - val_acc: 0.4244\n",
      "Epoch 6/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.8538 - acc: 0.3794 - val_loss: 1.7477 - val_acc: 0.4216\n",
      "Epoch 7/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.8500 - acc: 0.3887 - val_loss: 1.6958 - val_acc: 0.4347\n",
      "Epoch 8/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.7748 - acc: 0.4161 - val_loss: 1.6426 - val_acc: 0.4328\n",
      "Epoch 9/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.7564 - acc: 0.4204 - val_loss: 1.6763 - val_acc: 0.4450\n",
      "Epoch 10/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.7149 - acc: 0.4370 - val_loss: 1.5852 - val_acc: 0.4618\n",
      "Epoch 11/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.6892 - acc: 0.4450 - val_loss: 1.6144 - val_acc: 0.4636\n",
      "Epoch 12/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.6995 - acc: 0.4516 - val_loss: 1.5271 - val_acc: 0.4832\n",
      "Epoch 13/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.6492 - acc: 0.4629 - val_loss: 1.5187 - val_acc: 0.4916\n",
      "Epoch 14/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.6154 - acc: 0.4762 - val_loss: 1.5018 - val_acc: 0.5037\n",
      "Epoch 15/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.5945 - acc: 0.4884 - val_loss: 1.4907 - val_acc: 0.5215\n",
      "Epoch 16/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.5810 - acc: 0.4928 - val_loss: 1.4929 - val_acc: 0.5196\n",
      "Epoch 17/50\n",
      "271/271 [==============================] - 559s 2s/step - loss: 1.5536 - acc: 0.5040 - val_loss: 1.4338 - val_acc: 0.5299\n",
      "Epoch 18/50\n",
      "271/271 [==============================] - 560s 2s/step - loss: 1.5195 - acc: 0.5114 - val_loss: 1.4519 - val_acc: 0.5121\n",
      "Epoch 19/50\n",
      "271/271 [==============================] - 560s 2s/step - loss: 1.5115 - acc: 0.5113 - val_loss: 1.4506 - val_acc: 0.5149\n",
      "Epoch 00019: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11cf5f390>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping_monitor = EarlyStopping(monitor='val_acc', patience=2, verbose=1)\n",
    "# build the model\n",
    "model = larger_model()\n",
    "\n",
    "model.fit_generator(train_generator, \n",
    "                    steps_per_epoch=4346//batch_size, \n",
    "                    epochs=50, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=1087//batch_size, \n",
    "                    callbacks=[early_stopping_monitor], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator = datagen.flow_from_directory(\n",
    "        'CAX_Superhero_Test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,  # only data, no labels\n",
    "        shuffle=False)  # keep data in same order as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probabilities = model.predict_generator(generator, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_prob = model.predict(x) \n",
    "y_classes = probabilities.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(data=np.column_stack((test_temp.index.values+1,pred_class)), \n",
    "                          columns=['ImageId', 'Label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
